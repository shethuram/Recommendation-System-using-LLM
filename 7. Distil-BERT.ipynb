{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "602000ce-d659-4a6e-8396-7b98627fd8e6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## MODEL DOWNLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30ce1bfe-c8a1-44dd-8f8e-a28d06ae063f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfc0b8f7a9d24312a34a98a85b053e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\typis\\PycharmProjects\\Classwork\\venv310\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\typis\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f21645a403146d19dc6710fbceedd9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c22c277cf94333afe6e8ac66b72bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e35fe874634801958bece773e1b1b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f6159347de4f8692cd2441d698d0b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "# Downloads & caches locally (usually in ~/.cache/huggingface/)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "model = DistilBertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2955091b-45c8-4208-ad1a-6e8a1b5cde2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(\"./distilbert_local\")\n",
    "model.save_pretrained(\"./distilbert_local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8f20c8-71e9-4512-92c5-a3f4932e92d6",
   "metadata": {},
   "source": [
    "## DATASET LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "324ff08f-f7de-4f1c-8cd0-6d7dafd8350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e61bb7f-2683-4072-a8e3-17b8ee0f76c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movies_sub.csv')\n",
    "u_item = pd.read_csv(\"u_item.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62a7dec8-2956-4639-9267-76d9d8fe07b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['movie id', 'movie title', 'release date', 'video release date',\n",
       "       'IMDb URL', 'unknown', 'Action', 'Adventure', 'Animation', 'Children's',\n",
       "       'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film Noir',\n",
       "       'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War',\n",
       "       'Western'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_item.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "165eff5b-feae-4dd6-a780-6b123efe8d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_item.rename(columns={'movie id': 'Movie_ID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a2df191-eef7-4af1-b9e0-6d4a7e24356d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Movie_Name</th>\n",
       "      <th>Llama Summary Few Shot</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>...</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>In a world where toys come to life, a showdown...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>When a secret weapon system, GoldenEye, is det...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>At the mysterious Mon Senor hotel, a young bel...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>In the town of Hollywood, where fame and wealt...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>In a chilling game of cat and mouse, a cunning...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Movie_ID         Movie_Name  \\\n",
       "0         1   Toy Story (1995)   \n",
       "1         2   GoldenEye (1995)   \n",
       "2         3  Four Rooms (1995)   \n",
       "3         4  Get Shorty (1995)   \n",
       "4         5     Copycat (1995)   \n",
       "\n",
       "                              Llama Summary Few Shot  Action  Adventure  \\\n",
       "0  In a world where toys come to life, a showdown...       0          0   \n",
       "1  When a secret weapon system, GoldenEye, is det...       1          1   \n",
       "2  At the mysterious Mon Senor hotel, a young bel...       0          0   \n",
       "3  In the town of Hollywood, where fame and wealt...       1          0   \n",
       "4  In a chilling game of cat and mouse, a cunning...       0          0   \n",
       "\n",
       "   Animation  Children's  Comedy  Crime  Documentary  ...  Fantasy  Film Noir  \\\n",
       "0          1           1       1      0            0  ...        0          0   \n",
       "1          0           0       0      0            0  ...        0          0   \n",
       "2          0           0       0      0            0  ...        0          0   \n",
       "3          0           0       1      0            0  ...        0          0   \n",
       "4          0           0       0      1            0  ...        0          0   \n",
       "\n",
       "   Horror  Musical  Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0       0        0        0        0       0         0    0        0  \n",
       "1       0        0        0        0       0         1    0        0  \n",
       "2       0        0        0        0       0         1    0        0  \n",
       "3       0        0        0        0       0         0    0        0  \n",
       "4       0        0        0        0       0         1    0        0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_cols = ['Action', 'Adventure', 'Animation', \"Children's\", 'Comedy',\n",
    "              'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film Noir',\n",
    "              'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
    "              'Thriller', 'War', 'Western']\n",
    "\n",
    "data = movies[['Movie_ID', 'Movie_Name', 'Llama Summary Few Shot']].merge(u_item[['Movie_ID'] + genre_cols], on='Movie_ID')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e80f126c-e6e1-4db9-b4c2-b726498f2073",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.sample(n=100, random_state=42).reset_index(drop=True)\n",
    "\n",
    "texts = data['Llama Summary Few Shot'].tolist()\n",
    "labels = data[genre_cols].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdd4435-889b-4c2a-92de-3c391ee1bd31",
   "metadata": {},
   "source": [
    "## MODEL IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93c6a2b7-0d7b-42f6-a8eb-43fb0e664466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at ./distilbert_local and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"./distilbert_local\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"./distilbert_local\", num_labels=len(genre_cols)).to(device)\n",
    "\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "\n",
    "# Move inputs to GPU if available\n",
    "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "labels = torch.tensor(labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cafe6697-0d56-4738-bdcc-ab7689484541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 1999, 1037,  ...,    0,    0,    0],\n",
       "         [ 101, 2043, 1037,  ...,    0,    0,    0],\n",
       "         [ 101, 2012, 1996,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 1999, 1996,  ...,    0,    0,    0],\n",
       "         [ 101, 1999, 1037,  ...,    0,    0,    0],\n",
       "         [ 101, 1037, 2136,  ...,    0,    0,    0]], device='cuda:0'),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b29d04-0501-4884-94ca-9bbf6ee42f23",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5dbffd56-b62e-4cc7-a0d8-9301140609e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 - Loss: 1.1085\n",
      "Epoch 2/15 - Loss: 0.8057\n",
      "Epoch 3/15 - Loss: 0.6569\n",
      "Epoch 4/15 - Loss: 0.6135\n",
      "Epoch 5/15 - Loss: 0.5983\n",
      "Epoch 6/15 - Loss: 0.5899\n",
      "Epoch 7/15 - Loss: 0.5905\n",
      "Epoch 8/15 - Loss: 0.5975\n",
      "Epoch 9/15 - Loss: 0.5884\n",
      "Epoch 10/15 - Loss: 0.5921\n",
      "Epoch 11/15 - Loss: 0.5894\n",
      "Epoch 12/15 - Loss: 0.5893\n",
      "Early stopping triggered!\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Prepare data loader\n",
    "dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n",
    "train_dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=4e-5)\n",
    "class_counts = labels.sum(dim=0)\n",
    "pos_weights = (len(labels) - class_counts) / (class_counts + 1e-5)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weights) # Handle multi-label classification correctly.\n",
    "\n",
    "# Initialize scheduler\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.1)  # Adjust the learning rate every 2 epochs\n",
    "\n",
    "# Early stopping setup\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "patience = 3  # Stop training if no improvement in loss for 2 consecutive epochs\n",
    "\n",
    "# Start training\n",
    "model.train()\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        input_ids, attention_mask, label = batch\n",
    "        output = model(input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(output.logits, label.float())\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Step the scheduler to adjust learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Early stopping check\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        patience_counter = 0  # Reset counter\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e0235b32-a71f-418e-b3fc-2a3b5f614e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5883693272627674"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71c3a0f9-cc09-44b6-859d-d8a1680680e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./distilbert_finetuned_local\\\\tokenizer_config.json',\n",
       " './distilbert_finetuned_local\\\\special_tokens_map.json',\n",
       " './distilbert_finetuned_local\\\\vocab.txt',\n",
       " './distilbert_finetuned_local\\\\added_tokens.json')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./distilbert_finetuned_local\")\n",
    "tokenizer.save_pretrained(\"./distilbert_finetuned_local\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dd7c64-4d50-46ee-a764-504972767e4a",
   "metadata": {},
   "source": [
    "### PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6a5c9a0-34ed-4324-a562-a9d750e90c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting genres: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1633/1633 [00:12<00:00, 127.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Movie_Name</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Movie_ID         Movie_Name  Action  Adventure  Animation  Children's  \\\n",
       "0         1   Toy Story (1995)       0          1          1           1   \n",
       "1         2   GoldenEye (1995)       0          1          1           0   \n",
       "2         3  Four Rooms (1995)       0          1          1           1   \n",
       "3         4  Get Shorty (1995)       0          0          1           1   \n",
       "4         5     Copycat (1995)       0          1          1           1   \n",
       "\n",
       "   Comedy  Crime  Documentary  Drama  Fantasy  Film Noir  Horror  Musical  \\\n",
       "0       0      1            0      0        1          0       1        1   \n",
       "1       0      1            0      0        1          1       1        1   \n",
       "2       0      1            0      0        1          0       1        1   \n",
       "3       0      1            0      0        1          1       1        1   \n",
       "4       0      1            0      0        1          1       1        1   \n",
       "\n",
       "   Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0        1       0         1    1        1  \n",
       "1        0        1       0         0    1        1  \n",
       "2        0        1       0         0    1        1  \n",
       "3        0        1       0         0    1        1  \n",
       "4        0        1       0         0    1        1  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad(): # Disables gradient tracking since we’re just predicting.\n",
    "    for text in tqdm(texts, desc=\"Predicting genres\"):\n",
    "        encoded = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(\"cuda\")\n",
    "        outputs = model(**encoded)\n",
    "        probs = torch.sigmoid(outputs.logits)\n",
    "        preds = (probs > 0.5).int().squeeze().tolist()\n",
    "        predictions.append(preds)\n",
    "\n",
    "df = pd.DataFrame(predictions, columns=genre_cols)\n",
    "df = pd.concat([data[[\"Movie_ID\", \"Movie_Name\"]], df], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c1947d-1ec5-4010-9d6a-55f6e169cff7",
   "metadata": {},
   "source": [
    "### CLASSIFICATION REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0565582-544a-41d7-81ef-095860d08eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Genre  Precision  Recall  F1-score\n",
      "0        Action       0.13    0.13      0.13\n",
      "1     Adventure       0.07    0.82      0.13\n",
      "2     Animation       0.02    0.93      0.05\n",
      "3    Children's       0.08    0.93      0.14\n",
      "4        Comedy       0.22    0.04      0.07\n",
      "5         Crime       0.07    1.00      0.12\n",
      "6   Documentary       0.11    0.02      0.03\n",
      "7         Drama       0.00    0.00      0.00\n",
      "8       Fantasy       0.01    1.00      0.03\n",
      "9     Film Noir       0.03    0.67      0.05\n",
      "10       Horror       0.05    1.00      0.10\n",
      "11      Musical       0.03    0.96      0.07\n",
      "12      Mystery       0.00    0.00      0.00\n",
      "13      Romance       0.16    0.96      0.27\n",
      "14       Sci-Fi       0.00    0.00      0.00\n",
      "15     Thriller       0.23    0.05      0.08\n",
      "16          War       0.04    1.00      0.08\n",
      "17      Western       0.02    0.74      0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\typis\\PycharmProjects\\Classwork\\venv310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\typis\\PycharmProjects\\Classwork\\venv310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\typis\\PycharmProjects\\Classwork\\venv310\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Ensure movies and df have the same genre columns\n",
    "genres_list = [\n",
    "    \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\", \n",
    "    \"Documentary\", \"Drama\", \"Fantasy\", \"Film Noir\", \"Horror\", \"Musical\", \n",
    "    \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "\n",
    "# Initialize result dictionary\n",
    "results = {\"Genre\": [], \"Precision\": [], \"Recall\": [], \"F1-score\": []}\n",
    "\n",
    "# Compute metrics for each genre\n",
    "for genre in genres_list:\n",
    "    precision = precision_score(data[genre], df[genre])\n",
    "    recall = recall_score(data[genre], df[genre])\n",
    "    f1 = f1_score(data[genre], df[genre])\n",
    "\n",
    "    # Store results rounded to 2 decimal places\n",
    "    results[\"Genre\"].append(genre)\n",
    "    results[\"Precision\"].append(round(precision, 2))\n",
    "    results[\"Recall\"].append(round(recall, 2))\n",
    "    results[\"F1-score\"].append(round(f1, 2))\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "metrics_df = pd.DataFrame(results)\n",
    "\n",
    "metrics_df.to_csv(\"DB_Classification_Score.csv\", index=False)\n",
    "\n",
    "# Display the result\n",
    "print(metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad88f43-8169-4d9d-b071-a87eda93f0fe",
   "metadata": {},
   "source": [
    "## HYPER-PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d9168e6b-98de-4f71-aff0-1bb68feb9d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting prettytable\n",
      "  Downloading prettytable-3.16.0-py3-none-any.whl.metadata (33 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from prettytable) (0.2.13)\n",
      "Downloading prettytable-3.16.0-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: prettytable\n",
      "Successfully installed prettytable-3.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93e1766b-bf2b-4a24-b642-e666d7fe3436",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from datasets) (2.1.2)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-19.0.1-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.16-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.4.3-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.3.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.19.0-cp312-cp312-win_amd64.whl.metadata (74 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading aiohttp-3.11.16-cp312-cp312-win_amd64.whl (438 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading pyarrow-19.0.1-cp312-cp312-win_amd64.whl (25.3 MB)\n",
      "   ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/25.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/25.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/25.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/25.3 MB 419.4 kB/s eta 0:00:59\n",
      "    --------------------------------------- 0.5/25.3 MB 419.4 kB/s eta 0:00:59\n",
      "    --------------------------------------- 0.5/25.3 MB 419.4 kB/s eta 0:00:59\n",
      "    --------------------------------------- 0.5/25.3 MB 419.4 kB/s eta 0:00:59\n",
      "   - -------------------------------------- 0.8/25.3 MB 338.9 kB/s eta 0:01:13\n",
      "   - -------------------------------------- 0.8/25.3 MB 338.9 kB/s eta 0:01:13\n",
      "   - -------------------------------------- 0.8/25.3 MB 338.9 kB/s eta 0:01:13\n",
      "   - -------------------------------------- 1.0/25.3 MB 370.1 kB/s eta 0:01:06\n",
      "   - -------------------------------------- 1.0/25.3 MB 370.1 kB/s eta 0:01:06\n",
      "   - -------------------------------------- 1.0/25.3 MB 370.1 kB/s eta 0:01:06\n",
      "   - -------------------------------------- 1.0/25.3 MB 370.1 kB/s eta 0:01:06\n",
      "   - -------------------------------------- 1.0/25.3 MB 370.1 kB/s eta 0:01:06\n",
      "   -- ------------------------------------- 1.3/25.3 MB 340.7 kB/s eta 0:01:11\n",
      "   -- ------------------------------------- 1.3/25.3 MB 340.7 kB/s eta 0:01:11\n",
      "   -- ------------------------------------- 1.3/25.3 MB 340.7 kB/s eta 0:01:11\n",
      "   -- ------------------------------------- 1.6/25.3 MB 354.0 kB/s eta 0:01:07\n",
      "   -- ------------------------------------- 1.6/25.3 MB 354.0 kB/s eta 0:01:07\n",
      "   -- ------------------------------------- 1.6/25.3 MB 354.0 kB/s eta 0:01:07\n",
      "   -- ------------------------------------- 1.6/25.3 MB 354.0 kB/s eta 0:01:07\n",
      "   -- ------------------------------------- 1.8/25.3 MB 341.3 kB/s eta 0:01:09\n",
      "   -- ------------------------------------- 1.8/25.3 MB 341.3 kB/s eta 0:01:09\n",
      "   -- ------------------------------------- 1.8/25.3 MB 341.3 kB/s eta 0:01:09\n",
      "   --- ------------------------------------ 2.1/25.3 MB 348.5 kB/s eta 0:01:07\n",
      "   --- ------------------------------------ 2.1/25.3 MB 348.5 kB/s eta 0:01:07\n",
      "   --- ------------------------------------ 2.1/25.3 MB 348.5 kB/s eta 0:01:07\n",
      "   --- ------------------------------------ 2.1/25.3 MB 348.5 kB/s eta 0:01:07\n",
      "   --- ------------------------------------ 2.4/25.3 MB 340.7 kB/s eta 0:01:08\n",
      "   --- ------------------------------------ 2.4/25.3 MB 340.7 kB/s eta 0:01:08\n",
      "   --- ------------------------------------ 2.4/25.3 MB 340.7 kB/s eta 0:01:08\n",
      "   --- ------------------------------------ 2.4/25.3 MB 340.7 kB/s eta 0:01:08\n",
      "   --- ------------------------------------ 2.4/25.3 MB 340.7 kB/s eta 0:01:08\n",
      "   ---- ----------------------------------- 2.6/25.3 MB 334.0 kB/s eta 0:01:08\n",
      "   ---- ----------------------------------- 2.6/25.3 MB 334.0 kB/s eta 0:01:08\n",
      "   ---- ----------------------------------- 2.6/25.3 MB 334.0 kB/s eta 0:01:08\n",
      "   ---- ----------------------------------- 2.9/25.3 MB 340.3 kB/s eta 0:01:06\n",
      "   ---- ----------------------------------- 2.9/25.3 MB 340.3 kB/s eta 0:01:06\n",
      "   ---- ----------------------------------- 2.9/25.3 MB 340.3 kB/s eta 0:01:06\n",
      "   ---- ----------------------------------- 2.9/25.3 MB 340.3 kB/s eta 0:01:06\n",
      "   ---- ----------------------------------- 3.1/25.3 MB 334.9 kB/s eta 0:01:06\n",
      "   ---- ----------------------------------- 3.1/25.3 MB 334.9 kB/s eta 0:01:06\n",
      "   ---- ----------------------------------- 3.1/25.3 MB 334.9 kB/s eta 0:01:06\n",
      "   ----- ---------------------------------- 3.4/25.3 MB 340.7 kB/s eta 0:01:05\n",
      "   ----- ---------------------------------- 3.4/25.3 MB 340.7 kB/s eta 0:01:05\n",
      "   ----- ---------------------------------- 3.4/25.3 MB 340.7 kB/s eta 0:01:05\n",
      "   ----- ---------------------------------- 3.4/25.3 MB 340.7 kB/s eta 0:01:05\n",
      "   ----- ---------------------------------- 3.7/25.3 MB 336.0 kB/s eta 0:01:05\n",
      "   ----- ---------------------------------- 3.7/25.3 MB 336.0 kB/s eta 0:01:05\n",
      "   ----- ---------------------------------- 3.7/25.3 MB 336.0 kB/s eta 0:01:05\n",
      "   ------ --------------------------------- 3.9/25.3 MB 340.9 kB/s eta 0:01:03\n",
      "   ------ --------------------------------- 3.9/25.3 MB 340.9 kB/s eta 0:01:03\n",
      "   ------ --------------------------------- 3.9/25.3 MB 340.9 kB/s eta 0:01:03\n",
      "   ------ --------------------------------- 3.9/25.3 MB 340.9 kB/s eta 0:01:03\n",
      "   ------ --------------------------------- 3.9/25.3 MB 340.9 kB/s eta 0:01:03\n",
      "   ------ --------------------------------- 4.2/25.3 MB 333.8 kB/s eta 0:01:04\n",
      "   ------ --------------------------------- 4.2/25.3 MB 333.8 kB/s eta 0:01:04\n",
      "   ------ --------------------------------- 4.2/25.3 MB 333.8 kB/s eta 0:01:04\n",
      "   ------- -------------------------------- 4.5/25.3 MB 338.5 kB/s eta 0:01:02\n",
      "   ------- -------------------------------- 4.5/25.3 MB 338.5 kB/s eta 0:01:02\n",
      "   ------- -------------------------------- 4.5/25.3 MB 338.5 kB/s eta 0:01:02\n",
      "   ------- -------------------------------- 4.7/25.3 MB 342.0 kB/s eta 0:01:01\n",
      "   ------- -------------------------------- 4.7/25.3 MB 342.0 kB/s eta 0:01:01\n",
      "   ------- -------------------------------- 4.7/25.3 MB 342.0 kB/s eta 0:01:01\n",
      "   ------- -------------------------------- 4.7/25.3 MB 342.0 kB/s eta 0:01:01\n",
      "   ------- -------------------------------- 4.7/25.3 MB 342.0 kB/s eta 0:01:01\n",
      "   ------- -------------------------------- 5.0/25.3 MB 338.5 kB/s eta 0:01:00\n",
      "   ------- -------------------------------- 5.0/25.3 MB 338.5 kB/s eta 0:01:00\n",
      "   ------- -------------------------------- 5.0/25.3 MB 338.5 kB/s eta 0:01:00\n",
      "   -------- ------------------------------- 5.2/25.3 MB 339.5 kB/s eta 0:00:59\n",
      "   -------- ------------------------------- 5.2/25.3 MB 339.5 kB/s eta 0:00:59\n",
      "   -------- ------------------------------- 5.2/25.3 MB 339.5 kB/s eta 0:00:59\n",
      "   -------- ------------------------------- 5.2/25.3 MB 339.5 kB/s eta 0:00:59\n",
      "   -------- ------------------------------- 5.2/25.3 MB 339.5 kB/s eta 0:00:59\n",
      "   -------- ------------------------------- 5.5/25.3 MB 336.6 kB/s eta 0:00:59\n",
      "   -------- ------------------------------- 5.5/25.3 MB 336.6 kB/s eta 0:00:59\n",
      "   --------- ------------------------------ 5.8/25.3 MB 340.1 kB/s eta 0:00:58\n",
      "   --------- ------------------------------ 5.8/25.3 MB 340.1 kB/s eta 0:00:58\n",
      "   --------- ------------------------------ 5.8/25.3 MB 340.1 kB/s eta 0:00:58\n",
      "   --------- ------------------------------ 5.8/25.3 MB 340.1 kB/s eta 0:00:58\n",
      "   --------- ------------------------------ 5.8/25.3 MB 340.1 kB/s eta 0:00:58\n",
      "   --------- ------------------------------ 6.0/25.3 MB 337.1 kB/s eta 0:00:58\n",
      "   --------- ------------------------------ 6.0/25.3 MB 337.1 kB/s eta 0:00:58\n",
      "   --------- ------------------------------ 6.0/25.3 MB 337.1 kB/s eta 0:00:58\n",
      "   --------- ------------------------------ 6.3/25.3 MB 340.3 kB/s eta 0:00:56\n",
      "   --------- ------------------------------ 6.3/25.3 MB 340.3 kB/s eta 0:00:56\n",
      "   --------- ------------------------------ 6.3/25.3 MB 340.3 kB/s eta 0:00:56\n",
      "   --------- ------------------------------ 6.3/25.3 MB 340.3 kB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 6.6/25.3 MB 337.2 kB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 6.6/25.3 MB 337.2 kB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 6.6/25.3 MB 337.2 kB/s eta 0:00:56\n",
      "   ---------- ----------------------------- 6.8/25.3 MB 340.2 kB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 6.8/25.3 MB 340.2 kB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 6.8/25.3 MB 340.2 kB/s eta 0:00:55\n",
      "   ---------- ----------------------------- 6.8/25.3 MB 340.2 kB/s eta 0:00:55\n",
      "   ----------- ---------------------------- 7.1/25.3 MB 337.9 kB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 7.1/25.3 MB 337.9 kB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 7.1/25.3 MB 337.9 kB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 7.1/25.3 MB 337.9 kB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 7.1/25.3 MB 337.9 kB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 7.3/25.3 MB 335.5 kB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 7.3/25.3 MB 335.5 kB/s eta 0:00:54\n",
      "   ----------- ---------------------------- 7.3/25.3 MB 335.5 kB/s eta 0:00:54\n",
      "   ------------ --------------------------- 7.6/25.3 MB 338.0 kB/s eta 0:00:53\n",
      "   ------------ --------------------------- 7.6/25.3 MB 338.0 kB/s eta 0:00:53\n",
      "   ------------ --------------------------- 7.6/25.3 MB 338.0 kB/s eta 0:00:53\n",
      "   ------------ --------------------------- 7.6/25.3 MB 338.0 kB/s eta 0:00:53\n",
      "   ------------ --------------------------- 7.9/25.3 MB 335.8 kB/s eta 0:00:52\n",
      "   ------------ --------------------------- 7.9/25.3 MB 335.8 kB/s eta 0:00:52\n",
      "   ------------ --------------------------- 7.9/25.3 MB 335.8 kB/s eta 0:00:52\n",
      "   ------------ --------------------------- 8.1/25.3 MB 338.2 kB/s eta 0:00:51\n",
      "   ------------ --------------------------- 8.1/25.3 MB 338.2 kB/s eta 0:00:51\n",
      "   ------------ --------------------------- 8.1/25.3 MB 338.2 kB/s eta 0:00:51\n",
      "   ------------ --------------------------- 8.1/25.3 MB 338.2 kB/s eta 0:00:51\n",
      "   ------------ --------------------------- 8.1/25.3 MB 338.2 kB/s eta 0:00:51\n",
      "   ------------- -------------------------- 8.4/25.3 MB 334.9 kB/s eta 0:00:51\n",
      "   ------------- -------------------------- 8.4/25.3 MB 334.9 kB/s eta 0:00:51\n",
      "   ------------- -------------------------- 8.4/25.3 MB 334.9 kB/s eta 0:00:51\n",
      "   ------------- -------------------------- 8.7/25.3 MB 337.0 kB/s eta 0:00:50\n",
      "   ------------- -------------------------- 8.7/25.3 MB 337.0 kB/s eta 0:00:50\n",
      "   ------------- -------------------------- 8.7/25.3 MB 337.0 kB/s eta 0:00:50\n",
      "   ------------- -------------------------- 8.7/25.3 MB 337.0 kB/s eta 0:00:50\n",
      "   -------------- ------------------------- 8.9/25.3 MB 335.1 kB/s eta 0:00:49\n",
      "   -------------- ------------------------- 8.9/25.3 MB 335.1 kB/s eta 0:00:49\n",
      "   -------------- ------------------------- 8.9/25.3 MB 335.1 kB/s eta 0:00:49\n",
      "   -------------- ------------------------- 9.2/25.3 MB 337.3 kB/s eta 0:00:48\n",
      "   -------------- ------------------------- 9.2/25.3 MB 337.3 kB/s eta 0:00:48\n",
      "   -------------- ------------------------- 9.2/25.3 MB 337.3 kB/s eta 0:00:48\n",
      "   -------------- ------------------------- 9.2/25.3 MB 337.3 kB/s eta 0:00:48\n",
      "   -------------- ------------------------- 9.2/25.3 MB 337.3 kB/s eta 0:00:48\n",
      "   -------------- ------------------------- 9.4/25.3 MB 335.2 kB/s eta 0:00:48\n",
      "   -------------- ------------------------- 9.4/25.3 MB 335.2 kB/s eta 0:00:48\n",
      "   -------------- ------------------------- 9.4/25.3 MB 335.2 kB/s eta 0:00:48\n",
      "   --------------- ------------------------ 9.7/25.3 MB 337.6 kB/s eta 0:00:47\n",
      "   --------------- ------------------------ 9.7/25.3 MB 337.6 kB/s eta 0:00:47\n",
      "   --------------- ------------------------ 9.7/25.3 MB 337.6 kB/s eta 0:00:47\n",
      "   --------------- ------------------------ 9.7/25.3 MB 337.6 kB/s eta 0:00:47\n",
      "   --------------- ------------------------ 10.0/25.3 MB 335.7 kB/s eta 0:00:46\n",
      "   --------------- ------------------------ 10.0/25.3 MB 335.7 kB/s eta 0:00:46\n",
      "   --------------- ------------------------ 10.0/25.3 MB 335.7 kB/s eta 0:00:46\n",
      "   ---------------- ----------------------- 10.2/25.3 MB 337.7 kB/s eta 0:00:45\n",
      "   ---------------- ----------------------- 10.2/25.3 MB 337.7 kB/s eta 0:00:45\n",
      "   ---------------- ----------------------- 10.2/25.3 MB 337.7 kB/s eta 0:00:45\n",
      "   ---------------- ----------------------- 10.2/25.3 MB 337.7 kB/s eta 0:00:45\n",
      "   ---------------- ----------------------- 10.5/25.3 MB 334.3 kB/s eta 0:00:45\n",
      "   ---------------- ----------------------- 10.5/25.3 MB 334.3 kB/s eta 0:00:45\n",
      "   ---------------- ----------------------- 10.5/25.3 MB 334.3 kB/s eta 0:00:45\n",
      "   ----------------- ---------------------- 10.7/25.3 MB 337.7 kB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 10.7/25.3 MB 337.7 kB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 10.7/25.3 MB 337.7 kB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 10.7/25.3 MB 337.7 kB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 10.7/25.3 MB 337.7 kB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 11.0/25.3 MB 334.0 kB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 11.0/25.3 MB 334.0 kB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 11.0/25.3 MB 334.0 kB/s eta 0:00:43\n",
      "   ----------------- ---------------------- 11.3/25.3 MB 337.7 kB/s eta 0:00:42\n",
      "   ----------------- ---------------------- 11.3/25.3 MB 337.7 kB/s eta 0:00:42\n",
      "   ----------------- ---------------------- 11.3/25.3 MB 337.7 kB/s eta 0:00:42\n",
      "   ----------------- ---------------------- 11.3/25.3 MB 337.7 kB/s eta 0:00:42\n",
      "   ------------------ --------------------- 11.5/25.3 MB 334.7 kB/s eta 0:00:41\n",
      "   ------------------ --------------------- 11.5/25.3 MB 334.7 kB/s eta 0:00:41\n",
      "   ------------------ --------------------- 11.5/25.3 MB 334.7 kB/s eta 0:00:41\n",
      "   ------------------ --------------------- 11.5/25.3 MB 334.7 kB/s eta 0:00:41\n",
      "   ------------------ --------------------- 11.8/25.3 MB 334.1 kB/s eta 0:00:41\n",
      "   ------------------ --------------------- 11.8/25.3 MB 334.1 kB/s eta 0:00:41\n",
      "   ------------------ --------------------- 11.8/25.3 MB 334.1 kB/s eta 0:00:41\n",
      "   ------------------ --------------------- 11.8/25.3 MB 334.1 kB/s eta 0:00:41\n",
      "   ------------------- -------------------- 12.1/25.3 MB 333.4 kB/s eta 0:00:40\n",
      "   ------------------- -------------------- 12.1/25.3 MB 333.4 kB/s eta 0:00:40\n",
      "   ------------------- -------------------- 12.1/25.3 MB 333.4 kB/s eta 0:00:40\n",
      "   ------------------- -------------------- 12.3/25.3 MB 336.6 kB/s eta 0:00:39\n",
      "   ------------------- -------------------- 12.3/25.3 MB 336.6 kB/s eta 0:00:39\n",
      "   ------------------- -------------------- 12.3/25.3 MB 336.6 kB/s eta 0:00:39\n",
      "   ------------------- -------------------- 12.3/25.3 MB 336.6 kB/s eta 0:00:39\n",
      "   ------------------- -------------------- 12.6/25.3 MB 336.4 kB/s eta 0:00:38\n",
      "   ------------------- -------------------- 12.6/25.3 MB 336.4 kB/s eta 0:00:38\n",
      "   ------------------- -------------------- 12.6/25.3 MB 336.4 kB/s eta 0:00:38\n",
      "   -------------------- ------------------- 12.8/25.3 MB 336.6 kB/s eta 0:00:37\n",
      "   -------------------- ------------------- 12.8/25.3 MB 336.6 kB/s eta 0:00:37\n",
      "   -------------------- ------------------- 12.8/25.3 MB 336.6 kB/s eta 0:00:37\n",
      "   -------------------- ------------------- 12.8/25.3 MB 336.6 kB/s eta 0:00:37\n",
      "   -------------------- ------------------- 13.1/25.3 MB 336.6 kB/s eta 0:00:37\n",
      "   -------------------- ------------------- 13.1/25.3 MB 336.6 kB/s eta 0:00:37\n",
      "   -------------------- ------------------- 13.1/25.3 MB 336.6 kB/s eta 0:00:37\n",
      "   -------------------- ------------------- 13.1/25.3 MB 336.6 kB/s eta 0:00:37\n",
      "   -------------------- ------------------- 13.1/25.3 MB 336.6 kB/s eta 0:00:37\n",
      "   --------------------- ------------------ 13.4/25.3 MB 333.3 kB/s eta 0:00:36\n",
      "   --------------------- ------------------ 13.4/25.3 MB 333.3 kB/s eta 0:00:36\n",
      "   --------------------- ------------------ 13.4/25.3 MB 333.3 kB/s eta 0:00:36\n",
      "   --------------------- ------------------ 13.6/25.3 MB 336.6 kB/s eta 0:00:35\n",
      "   --------------------- ------------------ 13.6/25.3 MB 336.6 kB/s eta 0:00:35\n",
      "   --------------------- ------------------ 13.6/25.3 MB 336.6 kB/s eta 0:00:35\n",
      "   --------------------- ------------------ 13.6/25.3 MB 336.6 kB/s eta 0:00:35\n",
      "   ---------------------- ----------------- 13.9/25.3 MB 333.3 kB/s eta 0:00:35\n",
      "   ---------------------- ----------------- 13.9/25.3 MB 333.3 kB/s eta 0:00:35\n",
      "   ---------------------- ----------------- 13.9/25.3 MB 333.3 kB/s eta 0:00:35\n",
      "   ---------------------- ----------------- 14.2/25.3 MB 337.7 kB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 14.2/25.3 MB 337.7 kB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 14.2/25.3 MB 337.7 kB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 14.2/25.3 MB 337.7 kB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 14.2/25.3 MB 337.7 kB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 14.4/25.3 MB 334.1 kB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 14.4/25.3 MB 334.1 kB/s eta 0:00:33\n",
      "   ---------------------- ----------------- 14.4/25.3 MB 334.1 kB/s eta 0:00:33\n",
      "   ----------------------- ---------------- 14.7/25.3 MB 334.3 kB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 14.7/25.3 MB 334.3 kB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 14.7/25.3 MB 334.3 kB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 14.7/25.3 MB 334.3 kB/s eta 0:00:32\n",
      "   ----------------------- ---------------- 14.9/25.3 MB 334.3 kB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 14.9/25.3 MB 334.3 kB/s eta 0:00:31\n",
      "   ----------------------- ---------------- 14.9/25.3 MB 334.3 kB/s eta 0:00:31\n",
      "   ------------------------ --------------- 15.2/25.3 MB 335.5 kB/s eta 0:00:30\n",
      "   ------------------------ --------------- 15.2/25.3 MB 335.5 kB/s eta 0:00:30\n",
      "   ------------------------ --------------- 15.2/25.3 MB 335.5 kB/s eta 0:00:30\n",
      "   ------------------------ --------------- 15.2/25.3 MB 335.5 kB/s eta 0:00:30\n",
      "   ------------------------ --------------- 15.5/25.3 MB 335.5 kB/s eta 0:00:30\n",
      "   ------------------------ --------------- 15.5/25.3 MB 335.5 kB/s eta 0:00:30\n",
      "   ------------------------ --------------- 15.5/25.3 MB 335.5 kB/s eta 0:00:30\n",
      "   ------------------------ --------------- 15.7/25.3 MB 335.5 kB/s eta 0:00:29\n",
      "   ------------------------ --------------- 15.7/25.3 MB 335.5 kB/s eta 0:00:29\n",
      "   ------------------------ --------------- 15.7/25.3 MB 335.5 kB/s eta 0:00:29\n",
      "   ------------------------ --------------- 15.7/25.3 MB 335.5 kB/s eta 0:00:29\n",
      "   ------------------------ --------------- 15.7/25.3 MB 335.5 kB/s eta 0:00:29\n",
      "   ------------------------- -------------- 16.0/25.3 MB 335.5 kB/s eta 0:00:28\n",
      "   ------------------------- -------------- 16.0/25.3 MB 335.5 kB/s eta 0:00:28\n",
      "   ------------------------- -------------- 16.0/25.3 MB 335.5 kB/s eta 0:00:28\n",
      "   ------------------------- -------------- 16.0/25.3 MB 335.5 kB/s eta 0:00:28\n",
      "   ------------------------- -------------- 16.3/25.3 MB 332.0 kB/s eta 0:00:28\n",
      "   ------------------------- -------------- 16.3/25.3 MB 332.0 kB/s eta 0:00:28\n",
      "   ------------------------- -------------- 16.3/25.3 MB 332.0 kB/s eta 0:00:28\n",
      "   -------------------------- ------------- 16.5/25.3 MB 335.5 kB/s eta 0:00:27\n",
      "   -------------------------- ------------- 16.5/25.3 MB 335.5 kB/s eta 0:00:27\n",
      "   -------------------------- ------------- 16.5/25.3 MB 335.5 kB/s eta 0:00:27\n",
      "   -------------------------- ------------- 16.5/25.3 MB 335.5 kB/s eta 0:00:27\n",
      "   -------------------------- ------------- 16.8/25.3 MB 332.2 kB/s eta 0:00:26\n",
      "   -------------------------- ------------- 16.8/25.3 MB 332.2 kB/s eta 0:00:26\n",
      "   -------------------------- ------------- 16.8/25.3 MB 332.2 kB/s eta 0:00:26\n",
      "   -------------------------- ------------- 17.0/25.3 MB 335.2 kB/s eta 0:00:25\n",
      "   -------------------------- ------------- 17.0/25.3 MB 335.2 kB/s eta 0:00:25\n",
      "   -------------------------- ------------- 17.0/25.3 MB 335.2 kB/s eta 0:00:25\n",
      "   -------------------------- ------------- 17.0/25.3 MB 335.2 kB/s eta 0:00:25\n",
      "   -------------------------- ------------- 17.0/25.3 MB 335.2 kB/s eta 0:00:25\n",
      "   --------------------------- ------------ 17.3/25.3 MB 335.4 kB/s eta 0:00:24\n",
      "   --------------------------- ------------ 17.3/25.3 MB 335.4 kB/s eta 0:00:24\n",
      "   --------------------------- ------------ 17.3/25.3 MB 335.4 kB/s eta 0:00:24\n",
      "   --------------------------- ------------ 17.6/25.3 MB 334.3 kB/s eta 0:00:23\n",
      "   --------------------------- ------------ 17.6/25.3 MB 334.3 kB/s eta 0:00:23\n",
      "   --------------------------- ------------ 17.6/25.3 MB 334.3 kB/s eta 0:00:23\n",
      "   ---------------------------- ----------- 17.8/25.3 MB 337.7 kB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 17.8/25.3 MB 337.7 kB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 17.8/25.3 MB 337.7 kB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 17.8/25.3 MB 337.7 kB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 17.8/25.3 MB 337.7 kB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 18.1/25.3 MB 334.3 kB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 18.1/25.3 MB 334.3 kB/s eta 0:00:22\n",
      "   ---------------------------- ----------- 18.1/25.3 MB 334.3 kB/s eta 0:00:22\n",
      "   ----------------------------- ---------- 18.4/25.3 MB 337.5 kB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 18.4/25.3 MB 337.5 kB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 18.4/25.3 MB 337.5 kB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 18.4/25.3 MB 337.5 kB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 18.4/25.3 MB 337.5 kB/s eta 0:00:21\n",
      "   ----------------------------- ---------- 18.6/25.3 MB 334.3 kB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 18.6/25.3 MB 334.3 kB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 18.6/25.3 MB 334.3 kB/s eta 0:00:20\n",
      "   ----------------------------- ---------- 18.9/25.3 MB 337.5 kB/s eta 0:00:19\n",
      "   ----------------------------- ---------- 18.9/25.3 MB 337.5 kB/s eta 0:00:19\n",
      "   ----------------------------- ---------- 18.9/25.3 MB 337.5 kB/s eta 0:00:19\n",
      "   ----------------------------- ---------- 18.9/25.3 MB 337.5 kB/s eta 0:00:19\n",
      "   ------------------------------ --------- 19.1/25.3 MB 334.1 kB/s eta 0:00:19\n",
      "   ------------------------------ --------- 19.1/25.3 MB 334.1 kB/s eta 0:00:19\n",
      "   ------------------------------ --------- 19.1/25.3 MB 334.1 kB/s eta 0:00:19\n",
      "   ------------------------------ --------- 19.4/25.3 MB 338.0 kB/s eta 0:00:18\n",
      "   ------------------------------ --------- 19.4/25.3 MB 338.0 kB/s eta 0:00:18\n",
      "   ------------------------------ --------- 19.4/25.3 MB 338.0 kB/s eta 0:00:18\n",
      "   ------------------------------ --------- 19.4/25.3 MB 338.0 kB/s eta 0:00:18\n",
      "   ------------------------------- -------- 19.7/25.3 MB 334.3 kB/s eta 0:00:17\n",
      "   ------------------------------- -------- 19.7/25.3 MB 334.3 kB/s eta 0:00:17\n",
      "   ------------------------------- -------- 19.7/25.3 MB 334.3 kB/s eta 0:00:17\n",
      "   ------------------------------- -------- 19.9/25.3 MB 337.7 kB/s eta 0:00:16\n",
      "   ------------------------------- -------- 19.9/25.3 MB 337.7 kB/s eta 0:00:16\n",
      "   ------------------------------- -------- 19.9/25.3 MB 337.7 kB/s eta 0:00:16\n",
      "   ------------------------------- -------- 19.9/25.3 MB 337.7 kB/s eta 0:00:16\n",
      "   ------------------------------- -------- 20.2/25.3 MB 334.3 kB/s eta 0:00:16\n",
      "   ------------------------------- -------- 20.2/25.3 MB 334.3 kB/s eta 0:00:16\n",
      "   ------------------------------- -------- 20.2/25.3 MB 334.3 kB/s eta 0:00:16\n",
      "   ------------------------------- -------- 20.2/25.3 MB 334.3 kB/s eta 0:00:16\n",
      "   ------------------------------- -------- 20.2/25.3 MB 334.3 kB/s eta 0:00:16\n",
      "   -------------------------------- ------- 20.4/25.3 MB 333.8 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 20.4/25.3 MB 333.8 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 20.4/25.3 MB 333.8 kB/s eta 0:00:15\n",
      "   -------------------------------- ------- 20.7/25.3 MB 335.0 kB/s eta 0:00:14\n",
      "   -------------------------------- ------- 20.7/25.3 MB 335.0 kB/s eta 0:00:14\n",
      "   -------------------------------- ------- 20.7/25.3 MB 335.0 kB/s eta 0:00:14\n",
      "   -------------------------------- ------- 20.7/25.3 MB 335.0 kB/s eta 0:00:14\n",
      "   --------------------------------- ------ 21.0/25.3 MB 334.5 kB/s eta 0:00:13\n",
      "   --------------------------------- ------ 21.0/25.3 MB 334.5 kB/s eta 0:00:13\n",
      "   --------------------------------- ------ 21.0/25.3 MB 334.5 kB/s eta 0:00:13\n",
      "   --------------------------------- ------ 21.0/25.3 MB 334.5 kB/s eta 0:00:13\n",
      "   --------------------------------- ------ 21.2/25.3 MB 332.2 kB/s eta 0:00:13\n",
      "   --------------------------------- ------ 21.2/25.3 MB 332.2 kB/s eta 0:00:13\n",
      "   --------------------------------- ------ 21.2/25.3 MB 332.2 kB/s eta 0:00:13\n",
      "   --------------------------------- ------ 21.2/25.3 MB 332.2 kB/s eta 0:00:13\n",
      "   --------------------------------- ------ 21.2/25.3 MB 332.2 kB/s eta 0:00:13\n",
      "   ---------------------------------- ----- 21.5/25.3 MB 332.1 kB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 21.5/25.3 MB 332.1 kB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 21.5/25.3 MB 332.1 kB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 21.5/25.3 MB 332.1 kB/s eta 0:00:12\n",
      "   ---------------------------------- ----- 21.8/25.3 MB 332.0 kB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 21.8/25.3 MB 332.0 kB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 21.8/25.3 MB 332.0 kB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 21.8/25.3 MB 332.0 kB/s eta 0:00:11\n",
      "   ---------------------------------- ----- 22.0/25.3 MB 328.8 kB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 22.0/25.3 MB 328.8 kB/s eta 0:00:10\n",
      "   ---------------------------------- ----- 22.0/25.3 MB 328.8 kB/s eta 0:00:10\n",
      "   ----------------------------------- ---- 22.3/25.3 MB 331.1 kB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 22.3/25.3 MB 331.1 kB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 22.3/25.3 MB 331.1 kB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 22.3/25.3 MB 331.1 kB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 22.5/25.3 MB 332.0 kB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 22.5/25.3 MB 332.0 kB/s eta 0:00:09\n",
      "   ----------------------------------- ---- 22.5/25.3 MB 332.0 kB/s eta 0:00:09\n",
      "   ------------------------------------ --- 22.8/25.3 MB 331.1 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 22.8/25.3 MB 331.1 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 22.8/25.3 MB 331.1 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 22.8/25.3 MB 331.1 kB/s eta 0:00:08\n",
      "   ------------------------------------ --- 23.1/25.3 MB 332.3 kB/s eta 0:00:07\n",
      "   ------------------------------------ --- 23.1/25.3 MB 332.3 kB/s eta 0:00:07\n",
      "   ------------------------------------ --- 23.1/25.3 MB 332.3 kB/s eta 0:00:07\n",
      "   ------------------------------------ --- 23.1/25.3 MB 332.3 kB/s eta 0:00:07\n",
      "   ------------------------------------ --- 23.3/25.3 MB 332.0 kB/s eta 0:00:06\n",
      "   ------------------------------------ --- 23.3/25.3 MB 332.0 kB/s eta 0:00:06\n",
      "   ------------------------------------ --- 23.3/25.3 MB 332.0 kB/s eta 0:00:06\n",
      "   ------------------------------------ --- 23.3/25.3 MB 332.0 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 23.6/25.3 MB 331.1 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 23.6/25.3 MB 331.1 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 23.6/25.3 MB 331.1 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 23.6/25.3 MB 331.1 kB/s eta 0:00:06\n",
      "   ------------------------------------- -- 23.9/25.3 MB 328.8 kB/s eta 0:00:05\n",
      "   ------------------------------------- -- 23.9/25.3 MB 328.8 kB/s eta 0:00:05\n",
      "   ------------------------------------- -- 23.9/25.3 MB 328.8 kB/s eta 0:00:05\n",
      "   ------------------------------------- -- 23.9/25.3 MB 328.8 kB/s eta 0:00:05\n",
      "   -------------------------------------- - 24.1/25.3 MB 330.0 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 24.1/25.3 MB 330.0 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 24.1/25.3 MB 330.0 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 24.1/25.3 MB 330.0 kB/s eta 0:00:04\n",
      "   -------------------------------------- - 24.4/25.3 MB 327.9 kB/s eta 0:00:03\n",
      "   -------------------------------------- - 24.4/25.3 MB 327.9 kB/s eta 0:00:03\n",
      "   -------------------------------------- - 24.4/25.3 MB 327.9 kB/s eta 0:00:03\n",
      "   ---------------------------------------  24.6/25.3 MB 329.0 kB/s eta 0:00:02\n",
      "   ---------------------------------------  24.6/25.3 MB 329.0 kB/s eta 0:00:02\n",
      "   ---------------------------------------  24.6/25.3 MB 329.0 kB/s eta 0:00:02\n",
      "   ---------------------------------------  24.6/25.3 MB 329.0 kB/s eta 0:00:02\n",
      "   ---------------------------------------  24.9/25.3 MB 327.7 kB/s eta 0:00:02\n",
      "   ---------------------------------------  24.9/25.3 MB 327.7 kB/s eta 0:00:02\n",
      "   ---------------------------------------  24.9/25.3 MB 327.7 kB/s eta 0:00:02\n",
      "   ---------------------------------------  24.9/25.3 MB 327.7 kB/s eta 0:00:02\n",
      "   ---------------------------------------- 25.3/25.3 MB 330.6 kB/s eta 0:00:00\n",
      "Using cached xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "Downloading multidict-6.4.3-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Downloading propcache-0.3.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Downloading yarl-1.19.0-cp312-cp312-win_amd64.whl (92 kB)\n",
      "Installing collected packages: xxhash, pyarrow, propcache, multidict, frozenlist, dill, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.16 aiosignal-1.3.2 datasets-3.5.0 dill-0.3.8 frozenlist-1.5.0 multidict-6.4.3 multiprocess-0.70.16 propcache-0.3.1 pyarrow-19.0.1 xxhash-3.5.0 yarl-1.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24f57416-61a5-410b-adf9-5324c6711ed8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from optuna) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from optuna) (2.0.39)\n",
      "Requirement already satisfied: tqdm in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
      "Downloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
      "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: Mako, colorlog, alembic, optuna\n",
      "Successfully installed Mako-1.3.10 alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1986aa1d-4887-43d5-b56b-7e99fea2603c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (4.51.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "   ---------------------------------------- 0.0/10.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.4 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/10.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/10.4 MB 279.8 kB/s eta 0:00:36\n",
      "   -- ------------------------------------- 0.5/10.4 MB 279.8 kB/s eta 0:00:36\n",
      "   -- ------------------------------------- 0.5/10.4 MB 279.8 kB/s eta 0:00:36\n",
      "   --- ------------------------------------ 0.8/10.4 MB 332.2 kB/s eta 0:00:29\n",
      "   --- ------------------------------------ 0.8/10.4 MB 332.2 kB/s eta 0:00:29\n",
      "   --- ------------------------------------ 0.8/10.4 MB 332.2 kB/s eta 0:00:29\n",
      "   --- ------------------------------------ 0.8/10.4 MB 332.2 kB/s eta 0:00:29\n",
      "   --- ------------------------------------ 0.8/10.4 MB 332.2 kB/s eta 0:00:29\n",
      "   ---- ----------------------------------- 1.0/10.4 MB 316.6 kB/s eta 0:00:30\n",
      "   ---- ----------------------------------- 1.0/10.4 MB 316.6 kB/s eta 0:00:30\n",
      "   ---- ----------------------------------- 1.0/10.4 MB 316.6 kB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 1.3/10.4 MB 337.3 kB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 1.3/10.4 MB 337.3 kB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 1.3/10.4 MB 337.3 kB/s eta 0:00:27\n",
      "   ----- ---------------------------------- 1.3/10.4 MB 337.3 kB/s eta 0:00:27\n",
      "   ------ --------------------------------- 1.6/10.4 MB 326.4 kB/s eta 0:00:27\n",
      "   ------ --------------------------------- 1.6/10.4 MB 326.4 kB/s eta 0:00:27\n",
      "   ------ --------------------------------- 1.6/10.4 MB 326.4 kB/s eta 0:00:27\n",
      "   ------ --------------------------------- 1.6/10.4 MB 326.4 kB/s eta 0:00:27\n",
      "   ------ --------------------------------- 1.6/10.4 MB 326.4 kB/s eta 0:00:27\n",
      "   ------- -------------------------------- 1.8/10.4 MB 318.6 kB/s eta 0:00:27\n",
      "   ------- -------------------------------- 1.8/10.4 MB 318.6 kB/s eta 0:00:27\n",
      "   ------- -------------------------------- 1.8/10.4 MB 318.6 kB/s eta 0:00:27\n",
      "   -------- ------------------------------- 2.1/10.4 MB 329.9 kB/s eta 0:00:26\n",
      "   -------- ------------------------------- 2.1/10.4 MB 329.9 kB/s eta 0:00:26\n",
      "   -------- ------------------------------- 2.1/10.4 MB 329.9 kB/s eta 0:00:26\n",
      "   -------- ------------------------------- 2.1/10.4 MB 329.9 kB/s eta 0:00:26\n",
      "   --------- ------------------------------ 2.4/10.4 MB 323.4 kB/s eta 0:00:25\n",
      "   --------- ------------------------------ 2.4/10.4 MB 323.4 kB/s eta 0:00:25\n",
      "   --------- ------------------------------ 2.4/10.4 MB 323.4 kB/s eta 0:00:25\n",
      "   ---------- ----------------------------- 2.6/10.4 MB 331.9 kB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 2.6/10.4 MB 331.9 kB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 2.6/10.4 MB 331.9 kB/s eta 0:00:24\n",
      "   ---------- ----------------------------- 2.6/10.4 MB 331.9 kB/s eta 0:00:24\n",
      "   ----------- ---------------------------- 2.9/10.4 MB 326.4 kB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 2.9/10.4 MB 326.4 kB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 2.9/10.4 MB 326.4 kB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 2.9/10.4 MB 326.4 kB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 2.9/10.4 MB 326.4 kB/s eta 0:00:23\n",
      "   ------------ --------------------------- 3.1/10.4 MB 322.1 kB/s eta 0:00:23\n",
      "   ------------ --------------------------- 3.1/10.4 MB 322.1 kB/s eta 0:00:23\n",
      "   ------------- -------------------------- 3.4/10.4 MB 328.4 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 3.4/10.4 MB 328.4 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 3.4/10.4 MB 328.4 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 3.4/10.4 MB 328.4 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 3.4/10.4 MB 328.4 kB/s eta 0:00:22\n",
      "   -------------- ------------------------- 3.7/10.4 MB 325.1 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 3.7/10.4 MB 325.1 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 3.7/10.4 MB 325.1 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 3.7/10.4 MB 325.1 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 3.7/10.4 MB 325.1 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 3.9/10.4 MB 319.1 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 3.9/10.4 MB 319.1 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 3.9/10.4 MB 319.1 kB/s eta 0:00:21\n",
      "   ---------------- ----------------------- 4.2/10.4 MB 325.1 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.2/10.4 MB 325.1 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.2/10.4 MB 325.1 kB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 4.5/10.4 MB 328.6 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.5/10.4 MB 328.6 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.5/10.4 MB 328.6 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.5/10.4 MB 328.6 kB/s eta 0:00:19\n",
      "   ------------------ --------------------- 4.7/10.4 MB 323.7 kB/s eta 0:00:18\n",
      "   ------------------ --------------------- 4.7/10.4 MB 323.7 kB/s eta 0:00:18\n",
      "   ------------------ --------------------- 4.7/10.4 MB 323.7 kB/s eta 0:00:18\n",
      "   ------------------- -------------------- 5.0/10.4 MB 328.2 kB/s eta 0:00:17\n",
      "   ------------------- -------------------- 5.0/10.4 MB 328.2 kB/s eta 0:00:17\n",
      "   ------------------- -------------------- 5.0/10.4 MB 328.2 kB/s eta 0:00:17\n",
      "   ------------------- -------------------- 5.0/10.4 MB 328.2 kB/s eta 0:00:17\n",
      "   ------------------- -------------------- 5.0/10.4 MB 328.2 kB/s eta 0:00:17\n",
      "   -------------------- ------------------- 5.2/10.4 MB 325.6 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 5.2/10.4 MB 325.6 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 5.2/10.4 MB 325.6 kB/s eta 0:00:16\n",
      "   --------------------- ------------------ 5.5/10.4 MB 329.3 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 5.5/10.4 MB 329.3 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 5.5/10.4 MB 329.3 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 5.5/10.4 MB 329.3 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 5.8/10.4 MB 326.8 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 5.8/10.4 MB 326.8 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 5.8/10.4 MB 326.8 kB/s eta 0:00:15\n",
      "   ----------------------- ---------------- 6.0/10.4 MB 330.4 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.0/10.4 MB 330.4 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.0/10.4 MB 330.4 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.0/10.4 MB 330.4 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.3/10.4 MB 328.1 kB/s eta 0:00:13\n",
      "   ------------------------ --------------- 6.3/10.4 MB 328.1 kB/s eta 0:00:13\n",
      "   ------------------------ --------------- 6.3/10.4 MB 328.1 kB/s eta 0:00:13\n",
      "   ------------------------ --------------- 6.3/10.4 MB 328.1 kB/s eta 0:00:13\n",
      "   ------------------------- -------------- 6.6/10.4 MB 327.9 kB/s eta 0:00:12\n",
      "   ------------------------- -------------- 6.6/10.4 MB 327.9 kB/s eta 0:00:12\n",
      "   ------------------------- -------------- 6.6/10.4 MB 327.9 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 6.8/10.4 MB 330.8 kB/s eta 0:00:11\n",
      "   -------------------------- ------------- 6.8/10.4 MB 330.8 kB/s eta 0:00:11\n",
      "   -------------------------- ------------- 6.8/10.4 MB 330.8 kB/s eta 0:00:11\n",
      "   -------------------------- ------------- 6.8/10.4 MB 330.8 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.1/10.4 MB 330.5 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.1/10.4 MB 330.5 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.1/10.4 MB 330.5 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.1/10.4 MB 330.5 kB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 7.3/10.4 MB 329.9 kB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 7.3/10.4 MB 329.9 kB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 7.3/10.4 MB 329.9 kB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 7.3/10.4 MB 329.9 kB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 7.6/10.4 MB 328.0 kB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 7.6/10.4 MB 328.0 kB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 7.6/10.4 MB 328.0 kB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 7.6/10.4 MB 328.0 kB/s eta 0:00:09\n",
      "   ------------------------------ --------- 7.9/10.4 MB 327.2 kB/s eta 0:00:08\n",
      "   ------------------------------ --------- 7.9/10.4 MB 327.2 kB/s eta 0:00:08\n",
      "   ------------------------------ --------- 7.9/10.4 MB 327.2 kB/s eta 0:00:08\n",
      "   ------------------------------ --------- 7.9/10.4 MB 327.2 kB/s eta 0:00:08\n",
      "   ------------------------------- -------- 8.1/10.4 MB 328.5 kB/s eta 0:00:07\n",
      "   ------------------------------- -------- 8.1/10.4 MB 328.5 kB/s eta 0:00:07\n",
      "   ------------------------------- -------- 8.1/10.4 MB 328.5 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 8.4/10.4 MB 328.8 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 8.4/10.4 MB 328.8 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 8.4/10.4 MB 328.8 kB/s eta 0:00:07\n",
      "   --------------------------------- ------ 8.7/10.4 MB 331.0 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 8.7/10.4 MB 331.0 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 8.7/10.4 MB 331.0 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 8.7/10.4 MB 331.0 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 8.7/10.4 MB 331.0 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 8.9/10.4 MB 327.6 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 8.9/10.4 MB 327.6 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 8.9/10.4 MB 327.6 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 8.9/10.4 MB 327.6 kB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 9.2/10.4 MB 329.2 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 9.2/10.4 MB 329.2 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 9.2/10.4 MB 329.2 kB/s eta 0:00:04\n",
      "   ------------------------------------ --- 9.4/10.4 MB 331.4 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 9.4/10.4 MB 331.4 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 9.4/10.4 MB 331.4 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 9.4/10.4 MB 331.4 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 9.7/10.4 MB 329.9 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 9.7/10.4 MB 329.9 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 9.7/10.4 MB 329.9 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 9.7/10.4 MB 329.9 kB/s eta 0:00:03\n",
      "   -------------------------------------- - 10.0/10.4 MB 329.7 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.0/10.4 MB 329.7 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.0/10.4 MB 329.7 kB/s eta 0:00:02\n",
      "   ---------------------------------------  10.2/10.4 MB 333.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.2/10.4 MB 333.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.4/10.4 MB 333.3 kB/s eta 0:00:00\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.51.2\n",
      "    Uninstalling transformers-4.51.2:\n",
      "      Successfully uninstalled transformers-4.51.2\n",
      "Successfully installed transformers-4.51.3\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1d1dd27-ce6e-48f0-bf62-349d9e0b2474",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f163795c-0eee-4e83-b373-5a0207497fd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers[torch]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers[torch]) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers[torch]) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers[torch]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers[torch]) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers[torch]) (2.5.1+cu121)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from transformers[torch]) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (7.0.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers[torch]) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from torch>=2.0->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from torch>=2.0->transformers[torch]) (70.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from requests->transformers[torch]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from requests->transformers[torch]) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from requests->transformers[torch]) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\typis\\pycharmprojects\\classwork\\venv310\\lib\\site-packages (from jinja2->torch>=2.0->transformers[torch]) (2.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8be3dabc-d7b4-468a-b72b-075d12e455cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: accelerate\n",
      "Version: 1.6.0\n",
      "Summary: Accelerate\n",
      "Home-page: https://github.com/huggingface/accelerate\n",
      "Author: The HuggingFace team\n",
      "Author-email: zach.mueller@huggingface.co\n",
      "License: Apache\n",
      "Location: C:\\Users\\typis\\PycharmProjects\\Classwork\\venv310\\Lib\\site-packages\n",
      "Requires: huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73466802-895b-4880-89a9-2ba55435650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"./distilbert_finetuned_local\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"./distilbert_finetuned_local\", num_labels=len(genre_cols), problem_type=\"multi_label_classification\").to(device)\n",
    "\n",
    "# Split the data\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    texts, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_labels = [list(map(float, lbl)) for lbl in train_labels]\n",
    "val_labels = [list(map(float, lbl)) for lbl in val_labels]\n",
    "\n",
    "# Tokenize\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Create HuggingFace datasets\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'input_ids': train_encodings['input_ids'],\n",
    "    'attention_mask': train_encodings['attention_mask'],\n",
    "    'labels': train_labels\n",
    "})\n",
    "val_dataset = Dataset.from_dict({\n",
    "    'input_ids': val_encodings['input_ids'],\n",
    "    'attention_mask': val_encodings['attention_mask'],\n",
    "    'labels': val_labels\n",
    "})\n",
    "\n",
    "# Final dictionary\n",
    "encoded_dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ae1d02f-d24c-454c-af36-f140b468dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = torch.sigmoid(torch.tensor(logits)).numpy()  # convert logits to probs\n",
    "    preds = (probs > 0.5).astype(int)                     # apply threshold\n",
    "    labels = np.array(labels)                            # ensure correct format\n",
    "\n",
    "    return {\n",
    "        'precision': precision_score(labels, preds, average='micro', zero_division=0),\n",
    "        'recall': recall_score(labels, preds, average='micro', zero_division=0),\n",
    "        'f1': f1_score(labels, preds, average='micro', zero_division=0),\n",
    "        'accuracy': accuracy_score(labels, preds)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35222370-1d19-4462-b2ff-f2f241e9dd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 11:28:07,877] A new study created in memory with name: no-name-1278f138-78fe-45a7-8f32-d203e3bb91e1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1972, 'grad_norm': 0.30486366152763367, 'learning_rate': 8.887883147393474e-06, 'epoch': 2.4390243902439024}\n",
      "{'train_runtime': 223.3458, 'train_samples_per_second': 17.542, 'train_steps_per_second': 0.551, 'train_loss': 0.18961629441113975, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 11:31:57,500] Trial 0 finished with value: 0.7352112676056338 and parameters: {'learning_rate': 4.5550401130391553e-05, 'batch_size': 32, 'weight_decay': 0.013398179910986284}. Best is trial 0 with value: 0.7352112676056338.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16484810411930084, 'eval_precision': 0.7352112676056338, 'eval_runtime': 5.31, 'eval_samples_per_second': 61.582, 'eval_steps_per_second': 2.072, 'epoch': 3.0}\n",
      "{'loss': 0.146, 'grad_norm': 0.41365566849708557, 'learning_rate': 1.8768384686755683e-05, 'epoch': 1.2195121951219512}\n",
      "{'loss': 0.1222, 'grad_norm': 0.47034579515457153, 'learning_rate': 6.000776056309641e-06, 'epoch': 2.4390243902439024}\n",
      "{'train_runtime': 118.792, 'train_samples_per_second': 32.982, 'train_steps_per_second': 2.071, 'train_loss': 0.12961342470432685, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 11:34:00,607] Trial 1 finished with value: 0.738498789346247 and parameters: {'learning_rate': 3.140831723089727e-05, 'batch_size': 16, 'weight_decay': 0.2206635125996341}. Best is trial 1 with value: 0.738498789346247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1506294161081314, 'eval_precision': 0.738498789346247, 'eval_runtime': 3.344, 'eval_samples_per_second': 97.787, 'eval_steps_per_second': 6.28, 'epoch': 3.0}\n",
      "{'loss': 0.1083, 'grad_norm': 0.6516855359077454, 'learning_rate': 1.4720747080344915e-05, 'epoch': 0.6097560975609756}\n",
      "{'loss': 0.0988, 'grad_norm': 0.5365845561027527, 'learning_rate': 1.0975009909773691e-05, 'epoch': 1.2195121951219512}\n",
      "{'loss': 0.0872, 'grad_norm': 0.7652616500854492, 'learning_rate': 7.2292727392024645e-06, 'epoch': 1.8292682926829267}\n",
      "{'loss': 0.0887, 'grad_norm': 1.0014033317565918, 'learning_rate': 3.4835355686312395e-06, 'epoch': 2.4390243902439024}\n",
      "{'train_runtime': 122.2247, 'train_samples_per_second': 32.056, 'train_steps_per_second': 4.025, 'train_loss': 0.09274790345168696, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 11:36:06,525] Trial 2 finished with value: 0.717439293598234 and parameters: {'learning_rate': 1.8429026879210428e-05, 'batch_size': 8, 'weight_decay': 0.056589226276404836}. Best is trial 1 with value: 0.738498789346247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.15313979983329773, 'eval_precision': 0.717439293598234, 'eval_runtime': 2.7908, 'eval_samples_per_second': 117.172, 'eval_steps_per_second': 14.691, 'epoch': 3.0}\n",
      "{'loss': 0.0724, 'grad_norm': 0.3626071810722351, 'learning_rate': 3.5701752804625565e-06, 'epoch': 2.4390243902439024}\n",
      "{'train_runtime': 215.7235, 'train_samples_per_second': 18.162, 'train_steps_per_second': 0.57, 'train_loss': 0.07134002592505478, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 11:39:47,697] Trial 3 finished with value: 0.7139737991266376 and parameters: {'learning_rate': 1.8297148312370602e-05, 'batch_size': 32, 'weight_decay': 0.08475810159645836}. Best is trial 1 with value: 0.738498789346247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.157895028591156, 'eval_precision': 0.7139737991266376, 'eval_runtime': 4.7792, 'eval_samples_per_second': 68.422, 'eval_steps_per_second': 2.302, 'epoch': 3.0}\n",
      "{'loss': 0.0614, 'grad_norm': 0.5271261930465698, 'learning_rate': 8.558425904363631e-06, 'epoch': 0.6097560975609756}\n",
      "{'loss': 0.0583, 'grad_norm': 0.7633628845214844, 'learning_rate': 6.380709389258382e-06, 'epoch': 1.2195121951219512}\n",
      "{'loss': 0.0534, 'grad_norm': 0.883817195892334, 'learning_rate': 4.202992874153132e-06, 'epoch': 1.8292682926829267}\n",
      "{'loss': 0.0572, 'grad_norm': 0.26929861307144165, 'learning_rate': 2.025276359047882e-06, 'epoch': 2.4390243902439024}\n",
      "{'train_runtime': 122.7711, 'train_samples_per_second': 31.913, 'train_steps_per_second': 4.007, 'train_loss': 0.05695636970240895, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 11:41:54,200] Trial 4 finished with value: 0.7044967880085653 and parameters: {'learning_rate': 1.0714365254317829e-05, 'batch_size': 8, 'weight_decay': 0.14093372565214513}. Best is trial 1 with value: 0.738498789346247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.16506220400333405, 'eval_precision': 0.7044967880085653, 'eval_runtime': 2.8196, 'eval_samples_per_second': 115.973, 'eval_steps_per_second': 14.541, 'epoch': 3.0}\n",
      "{'loss': 0.0507, 'grad_norm': 0.40542781352996826, 'learning_rate': 1.3766349194321545e-05, 'epoch': 1.2195121951219512}\n",
      "{'loss': 0.0461, 'grad_norm': 0.24830102920532227, 'learning_rate': 4.401485796823896e-06, 'epoch': 2.4390243902439024}\n",
      "{'train_runtime': 112.0484, 'train_samples_per_second': 34.967, 'train_steps_per_second': 2.195, 'train_loss': 0.04718332513561094, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 11:43:49,943] Trial 5 finished with value: 0.7103004291845494 and parameters: {'learning_rate': 2.303756395784422e-05, 'batch_size': 16, 'weight_decay': 0.19755231032106343}. Best is trial 1 with value: 0.738498789346247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1733478456735611, 'eval_precision': 0.7103004291845494, 'eval_runtime': 2.941, 'eval_samples_per_second': 111.187, 'eval_steps_per_second': 7.14, 'epoch': 3.0}\n",
      "{'loss': 0.0374, 'grad_norm': 0.15462477505207062, 'learning_rate': 1.1612003885646233e-05, 'epoch': 1.2195121951219512}\n",
      "{'loss': 0.0339, 'grad_norm': 0.3457781970500946, 'learning_rate': 3.71268151445832e-06, 'epoch': 2.4390243902439024}\n",
      "{'train_runtime': 111.8483, 'train_samples_per_second': 35.03, 'train_steps_per_second': 2.199, 'train_loss': 0.03506397764857223, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 11:45:45,639] Trial 6 finished with value: 0.6993603411513859 and parameters: {'learning_rate': 1.943233303312227e-05, 'batch_size': 16, 'weight_decay': 0.1910959300719705}. Best is trial 1 with value: 0.738498789346247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.18077149987220764, 'eval_precision': 0.6993603411513859, 'eval_runtime': 2.9453, 'eval_samples_per_second': 111.025, 'eval_steps_per_second': 7.13, 'epoch': 3.0}\n",
      "{'loss': 0.0279, 'grad_norm': 0.2649332582950592, 'learning_rate': 1.3189438184000173e-05, 'epoch': 1.2195121951219512}\n",
      "{'loss': 0.026, 'grad_norm': 0.21148839592933655, 'learning_rate': 4.217031256108899e-06, 'epoch': 2.4390243902439024}\n",
      "{'train_runtime': 111.9309, 'train_samples_per_second': 35.004, 'train_steps_per_second': 2.198, 'train_loss': 0.0265638285536107, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 11:47:41,428] Trial 7 finished with value: 0.7021276595744681 and parameters: {'learning_rate': 2.2072121042612536e-05, 'batch_size': 16, 'weight_decay': 0.2844028259370367}. Best is trial 1 with value: 0.738498789346247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19087469577789307, 'eval_precision': 0.7021276595744681, 'eval_runtime': 2.9707, 'eval_samples_per_second': 110.077, 'eval_steps_per_second': 7.069, 'epoch': 3.0}\n",
      "{'loss': 0.0242, 'grad_norm': 0.1868039220571518, 'learning_rate': 6.9114405226793635e-06, 'epoch': 2.4390243902439024}\n",
      "{'train_runtime': 188.3249, 'train_samples_per_second': 20.804, 'train_steps_per_second': 0.653, 'train_loss': 0.023334283169692126, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 11:50:53,451] Trial 8 finished with value: 0.6918367346938775 and parameters: {'learning_rate': 3.5421132678731735e-05, 'batch_size': 32, 'weight_decay': 0.07951492116176469}. Best is trial 1 with value: 0.738498789346247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.20247139036655426, 'eval_precision': 0.6918367346938775, 'eval_runtime': 2.8345, 'eval_samples_per_second': 115.366, 'eval_steps_per_second': 3.881, 'epoch': 3.0}\n",
      "{'loss': 0.0183, 'grad_norm': 0.35307103395462036, 'learning_rate': 1.8353387782633338e-05, 'epoch': 0.6097560975609756}\n",
      "{'loss': 0.0176, 'grad_norm': 0.14890389144420624, 'learning_rate': 1.3683314555500173e-05, 'epoch': 1.2195121951219512}\n",
      "{'loss': 0.0182, 'grad_norm': 0.3496118187904358, 'learning_rate': 9.013241328367007e-06, 'epoch': 1.8292682926829267}\n",
      "{'loss': 0.0167, 'grad_norm': 0.08236336708068848, 'learning_rate': 4.343168101233843e-06, 'epoch': 2.4390243902439024}\n",
      "{'train_runtime': 122.6753, 'train_samples_per_second': 31.938, 'train_steps_per_second': 4.011, 'train_loss': 0.01706998425770581, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-16 11:52:59,912] Trial 9 finished with value: 0.6821862348178138 and parameters: {'learning_rate': 2.297676027749517e-05, 'batch_size': 8, 'weight_decay': 0.15087534004209116}. Best is trial 1 with value: 0.738498789346247.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21954531967639923, 'eval_precision': 0.6821862348178138, 'eval_runtime': 2.7838, 'eval_samples_per_second': 117.465, 'eval_steps_per_second': 14.728, 'epoch': 3.0}\n",
      "Best Parameters: {'learning_rate': 3.140831723089727e-05, 'batch_size': 16, 'weight_decay': 0.2206635125996341}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from transformers import TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from sklearn.metrics import precision_score\n",
    "import numpy as np\n",
    "\n",
    "# Objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggesting hyperparameters\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 5e-5, log=True)  # picks from range\n",
    "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32])   # picks from list \n",
    "    weight_decay = trial.suggest_float('weight_decay', 0.0, 0.3)\n",
    "\n",
    "    # Define TrainingArguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./optuna_results\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=weight_decay,\n",
    "        save_strategy=\"steps\",          # Save model every few steps\n",
    "        save_steps=100,                 # Save every 100 steps\n",
    "        eval_strategy=\"steps\",         # Evaluate every few steps\n",
    "        eval_steps=100,                 # Evaluate every 100 steps\n",
    "        logging_steps=100,              # Log every 100 steps\n",
    "        load_best_model_at_end=True,    # Load best model at the end based on evaluation\n",
    "        disable_tqdm=True,              # Disable tqdm to avoid overloading output\n",
    "        report_to=\"none\",               # Disable logging to platforms like TensorBoard\n",
    ")\n",
    "\n",
    "    # Trainer setup\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=encoded_dataset['train'],\n",
    "        eval_dataset=encoded_dataset['validation'],\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    eval_results = trainer.evaluate()\n",
    "    return eval_results[\"eval_precision\"]  # Maximize precision\n",
    "\n",
    "# Run Optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Best Parameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "477d3be3-6dec-4235-8452-142aab98837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "best_params = {\n",
    "    \"learning_rate\": 3.140831723089727e-05,\n",
    "    \"batch_size\": 16,\n",
    "    \"weight_decay\": 0.2206635125996341\n",
    "}\n",
    "\n",
    "#with open(\"best_hyperparams.json\", \"w\") as f:\n",
    "#    json.dump(best_params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ccb9e7b3-d634-4b32-8577-7e823b05cdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"best_hyperparams.json\", \"r\") as f:\n",
    "#    best_params = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7cff8a1-9300-4c53-9038-9322feb960b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15 - Loss: 1.0377\n",
      "Epoch 2/15 - Loss: 0.8076\n",
      "Epoch 3/15 - Loss: 0.6648\n",
      "Epoch 4/15 - Loss: 0.6362\n",
      "Epoch 5/15 - Loss: 0.6210\n",
      "Epoch 6/15 - Loss: 0.6246\n",
      "Epoch 7/15 - Loss: 0.6171\n",
      "Epoch 8/15 - Loss: 0.6154\n",
      "Epoch 9/15 - Loss: 0.6180\n",
      "Epoch 10/15 - Loss: 0.6138\n",
      "Epoch 11/15 - Loss: 0.6148\n",
      "Epoch 12/15 - Loss: 0.6225\n",
      "Epoch 13/15 - Loss: 0.6121\n",
      "Epoch 14/15 - Loss: 0.6147\n",
      "Epoch 15/15 - Loss: 0.6167\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "\n",
    "# Move inputs to GPU if available\n",
    "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "labels = torch.tensor(labels).to(device)\n",
    "\n",
    "# Prepare data loader\n",
    "dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n",
    "train_dataloader = DataLoader(dataset, batch_size = best_params['batch_size'], shuffle=True)\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = best_params['learning_rate'], weight_decay = best_params['weight_decay'])\n",
    "class_counts = labels.sum(dim=0)\n",
    "pos_weights = (len(labels) - class_counts) / (class_counts + 1e-5)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weights) # Handle multi-label classification correctly.\n",
    "\n",
    "# Initialize scheduler\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.1)  # Adjust the learning rate every 2 epochs\n",
    "\n",
    "# Early stopping setup\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "patience = 3  # Stop training if no improvement in loss for 2 consecutive epochs\n",
    "\n",
    "# Start training\n",
    "model.train()\n",
    "epochs = 15\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_dataloader:\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        input_ids, attention_mask, label = batch\n",
    "        output = model(input_ids, attention_mask=attention_mask)\n",
    "        loss = loss_fn(output.logits, label.float())\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Step the scheduler to adjust learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    # Early stopping check\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        patience_counter = 0  # Reset counter\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4a84fc3-2980-45f4-ba2b-7a99852329d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6121297030194291"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ac2b24e-07ad-42c1-8086-d9e993aba328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting genres: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1633/1633 [00:38<00:00, 42.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Movie_Name</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>Animation</th>\n",
       "      <th>Children's</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Crime</th>\n",
       "      <th>Documentary</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Fantasy</th>\n",
       "      <th>Film Noir</th>\n",
       "      <th>Horror</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Mystery</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Movie_ID         Movie_Name  Action  Adventure  Animation  Children's  \\\n",
       "0         1   Toy Story (1995)       0          1          1           1   \n",
       "1         2   GoldenEye (1995)       1          1          0           0   \n",
       "2         3  Four Rooms (1995)       0          0          0           0   \n",
       "3         4  Get Shorty (1995)       0          0          0           0   \n",
       "4         5     Copycat (1995)       1          0          0           0   \n",
       "\n",
       "   Comedy  Crime  Documentary  Drama  Fantasy  Film Noir  Horror  Musical  \\\n",
       "0       1      0            0      0        1          0       0        1   \n",
       "1       0      0            0      0        0          1       1        0   \n",
       "2       1      0            0      0        0          0       0        0   \n",
       "3       1      1            0      0        0          1       0        0   \n",
       "4       0      1            0      0        0          1       0        0   \n",
       "\n",
       "   Mystery  Romance  Sci-Fi  Thriller  War  Western  \n",
       "0        0        0       1         0    1        0  \n",
       "1        1        0       1         1    0        0  \n",
       "2        0        0       0         0    0        0  \n",
       "3        1        0       0         1    0        0  \n",
       "4        1        0       0         1    0        0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad(): # Disables gradient tracking since we’re just predicting.\n",
    "    for text in tqdm(texts, desc=\"Predicting genres\"):\n",
    "        encoded = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(\"cuda\")\n",
    "        outputs = model(**encoded)\n",
    "        probs = torch.sigmoid(outputs.logits)\n",
    "        preds = (probs > 0.5).int().squeeze().tolist()\n",
    "        predictions.append(preds)\n",
    "\n",
    "df = pd.DataFrame(predictions, columns=genre_cols)\n",
    "df = pd.concat([data[[\"Movie_ID\", \"Movie_Name\"]], df], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efa45a1a-4f80-48ce-be9e-4acb68db1cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Genre  Precision  Recall  F1-score\n",
      "0        Action       0.40    0.84      0.54\n",
      "1     Adventure       0.37    0.90      0.52\n",
      "2     Animation       0.23    1.00      0.38\n",
      "3    Children's       0.48    0.95      0.64\n",
      "4        Comedy       0.64    0.76      0.69\n",
      "5         Crime       0.25    0.85      0.39\n",
      "6   Documentary       0.18    0.88      0.30\n",
      "7         Drama       0.73    0.81      0.77\n",
      "8       Fantasy       0.12    1.00      0.22\n",
      "9     Film Noir       0.08    1.00      0.16\n",
      "10       Horror       0.28    1.00      0.44\n",
      "11      Musical       0.18    0.89      0.30\n",
      "12      Mystery       0.16    0.90      0.27\n",
      "13      Romance       0.32    0.71      0.45\n",
      "14       Sci-Fi       0.31    0.96      0.47\n",
      "15     Thriller       0.42    0.86      0.56\n",
      "16          War       0.24    0.86      0.38\n",
      "17      Western       0.18    0.96      0.30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "genres_list = [\n",
    "    \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\", \n",
    "    \"Documentary\", \"Drama\", \"Fantasy\", \"Film Noir\", \"Horror\", \"Musical\", \n",
    "    \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "\n",
    "# Initialize result dictionary\n",
    "results = {\"Genre\": [], \"Precision\": [], \"Recall\": [], \"F1-score\": []}\n",
    "\n",
    "# Compute metrics for each genre\n",
    "for genre in genres_list:\n",
    "    precision = precision_score(data[genre], df[genre])\n",
    "    recall = recall_score(data[genre], df[genre])\n",
    "    f1 = f1_score(data[genre], df[genre])\n",
    "\n",
    "    # Store results rounded to 2 decimal places\n",
    "    results[\"Genre\"].append(genre)\n",
    "    results[\"Precision\"].append(round(precision, 2))\n",
    "    results[\"Recall\"].append(round(recall, 2))\n",
    "    results[\"F1-score\"].append(round(f1, 2))\n",
    "\n",
    "# Convert results into a DataFrame\n",
    "metrics_df = pd.DataFrame(results)\n",
    "\n",
    "metrics_df.to_csv(\"DB_Classification_Score.csv\", index=False)\n",
    "\n",
    "# Display the result\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef487ca6-a55e-4e55-a8e6-d8ec08e8cb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./distilbert_HPT_local\\\\tokenizer_config.json',\n",
       " './distilbert_HPT_local\\\\special_tokens_map.json',\n",
       " './distilbert_HPT_local\\\\vocab.txt',\n",
       " './distilbert_HPT_local\\\\added_tokens.json')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./distilbert_HPT_local\")\n",
    "tokenizer.save_pretrained(\"./distilbert_HPT_local\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
